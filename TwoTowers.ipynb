{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#Analogue of the nn.RNN module\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, nonlinearity='tanh'):\n",
    "        super(MyRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.weight_ih = nn.Parameter(torch.Tensor(num_layers, hidden_size, input_size))\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(num_layers, hidden_size, hidden_size))\n",
    "        if bias:\n",
    "            self.bias_ih = nn.Parameter(torch.Tensor(num_layers, hidden_size))\n",
    "            self.bias_hh = nn.Parameter(torch.Tensor(num_layers, hidden_size))\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "\n",
    "        self.nonlinearity = nonlinearity\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / (self.hidden_size ** 0.5)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        '''\n",
    "        This function defines a forward RNN pass  \n",
    "\n",
    "        Input: tensor of shape (batch_size, sequence_length, input_size)'\n",
    "        Output: (output, hx) where output is a list of tensors oh  cell\n",
    "        predictions, shape (num_layers, batch_size, hidden_size)\n",
    "        '''\n",
    "        # Initializes the hidden state if not provided\n",
    "        if hx is None:\n",
    "            hx = torch.zeros(self.num_layers, input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        #iterate over each time step\n",
    "        for i in range(input.size(1)):\n",
    "            hx = self.rnn_cell(input[:, i, :], hx)\n",
    "            outputs.append(hx.unsqueeze(1))\n",
    "\n",
    "        output = torch.cat(outputs, dim=1)\n",
    "        return output, hx\n",
    "\n",
    "    def rnn_cell(self, input, hx):\n",
    "        '''\n",
    "        Defines a run of one RNN batch for one time step\n",
    "\n",
    "        Inputs: \n",
    "            input tensor of hape (batch_size, 1, input_size)\n",
    "            hx tensor of shape (num_layers, batch_size, hidden_size)\n",
    "        Output:\n",
    "            tensor of shape (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        '''\n",
    "        # Apply RNN cell computation  --> tensor (batch_size, hidden_size)\n",
    "        gates = torch.matmul(input, self.weight_ih.transpose(0, 1)) + torch.matmul(hx, self.weight_hh.transpose(0, 1))\n",
    "        if self.bias_ih is not None:\n",
    "            gates += self.bias_ih.unsqueeze(0)\n",
    "            gates += self.bias_hh.unsqueeze(0)\n",
    "        if self.nonlinearity == 'tanh':\n",
    "            return torch.tanh(gates)\n",
    "        elif self.nonlinearity == 'relu':\n",
    "            return torch.relu(gates)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported nonlinearity. Choose from 'tanh' or 'relu'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class fullRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(fullRNN, self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.rnn_cell=nn.RNN(input_size, hidden_size)\n",
    "        self.output_layer=nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, ordered_text):\n",
    "        '''\n",
    "        This functions defines forward prop through our RNN network.\n",
    "        The input is a tensor of shape (seq_length, batch_size, input_size)\n",
    "        The seq_length is number of examples\n",
    "        '''\n",
    "        #Initiates the hidden layer for the whole text\n",
    "        print(ordered_text.shape())\n",
    "        ordered_text = ordered_text.unsqueeze(1)  # Adds a batch dimension\n",
    "        hidden = torch.zeros(1, ordered_text.size(1), self.hidden_size)\n",
    "        # hidden=torch.zeros (ordered_text.size(1), self.hidden_size)\n",
    "        rnn_output, hidden = self.rnn_cell(ordered_text, hidden)\n",
    "        output=self.output_layer(rnn_output[-1, :, :])\n",
    "        return output\n",
    "\n",
    "input_size = 128\n",
    "hidden_size = 100\n",
    "output_size = 100\n",
    "\n",
    "# Step 1 - Create RNN for Query Tower + for Doc tower \n",
    "queryRNN = fullRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Step 2 - Load input data - pickle files have been tokenised by sentence piece and embedded by\n",
    "# Data in format - [tesnor([tensor(query), tensor(rel_docs), tensor(irr_docs)]), .... ]\n",
    "# For query\n",
    "testData = []\n",
    "trainingData = [] \n",
    "# To prep the data\n",
    "validationData = []\n",
    "\n",
    "with open('tokenised_triplets/test.pkl', 'rb') as file:\n",
    "    testData = pickle.load(file)\n",
    "with open('tokenised_triplets/training.pkl', 'rb') as file:\n",
    "    trainingData = pickle.load(file)\n",
    "with open('tokenised_triplets/validation.pkl', 'rb') as file:\n",
    "    validationData = pickle.load(file)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0450, -0.1094,  0.2346,  ...,  0.1490, -0.1885, -0.0019],\n",
      "        [ 0.0450, -0.1094,  0.2346,  ...,  0.1490, -0.1885, -0.0019],\n",
      "        [ 0.0450, -0.1094,  0.2346,  ...,  0.1490, -0.1885, -0.0019],\n",
      "        ...,\n",
      "        [-0.0671, -0.1579,  0.3436,  ...,  0.0970, -0.0428, -0.2825],\n",
      "        [-0.0671, -0.1579,  0.3436,  ...,  0.0970, -0.0428, -0.2825],\n",
      "        [-0.0671, -0.1579,  0.3436,  ...,  0.0970, -0.0428, -0.2825]])\n"
     ]
    }
   ],
   "source": [
    "# Take the query out of the triplet \n",
    "query_list = []\n",
    "for (query, _, _ ) in trainingData:\n",
    "#  This gives tensor([w1, w2, w3,...wn]) for each individual query\n",
    "# Take the query out of a tensor form and keep as a list\n",
    "    query_as_list = query.tolist()\n",
    "# Then iterate over all of the triplets and pull them all out \n",
    "    query_list.append(query_as_list)\n",
    "# Put them all in one list \n",
    "# Make this list a tensor\n",
    "tensor_query_list = torch.tensor(query_list)\n",
    "print(tensor_query_list)\n",
    "# Put into model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([814, 128])\n",
      "torch.Size([128])\n",
      "tensor([ 4.5037e-02, -1.0937e-01,  2.3464e-01,  2.8838e-01,  2.1045e-01,\n",
      "        -3.6086e-02, -3.6875e-02, -1.3356e-01, -1.8880e-02, -3.9864e-02,\n",
      "         2.0278e-01, -9.6033e-04, -1.8266e-01,  4.3697e-02,  7.3484e-02,\n",
      "         1.6414e-01, -1.6777e-01,  1.0787e-01, -2.3564e-01,  3.5150e-01,\n",
      "         5.3646e-02, -1.8614e-01, -2.8010e-01, -3.0639e-01, -1.3082e-01,\n",
      "         6.8598e-02, -1.4798e-01,  3.2496e-02,  1.7219e-01, -8.9243e-02,\n",
      "        -1.1667e-01,  7.7255e-03,  6.9057e-02, -2.2016e-04,  5.5669e-02,\n",
      "         1.9851e-01,  8.6366e-02, -1.1740e-01, -6.8780e-02, -1.2199e-01,\n",
      "        -1.3029e-01,  4.2058e-01,  9.6036e-02,  7.6770e-02,  2.1897e-01,\n",
      "        -1.2299e-01, -8.5546e-02,  3.8775e-02,  1.7612e-01,  2.7531e-01,\n",
      "        -3.0188e-01,  6.1773e-02,  2.6999e-01,  1.7055e-01,  3.0800e-01,\n",
      "         1.4514e-01,  1.6264e-02, -2.5426e-01, -2.3492e-01,  1.1858e-01,\n",
      "        -5.6707e-02, -4.4231e-02,  1.8520e-01, -8.9252e-02,  1.6647e-01,\n",
      "         8.2960e-02, -1.3074e-01,  1.8039e-01, -3.1456e-02,  1.3525e-01,\n",
      "        -3.5984e-01, -1.1043e-01, -2.3497e-01, -1.6297e-02,  1.1886e-01,\n",
      "        -3.3533e-01, -3.4823e-02,  1.1884e-02,  1.4163e-01,  2.0241e-01,\n",
      "        -2.0603e-01, -3.4023e-01,  6.2919e-02,  1.9404e-01,  4.4208e-02,\n",
      "         8.4311e-02,  3.5661e-01, -1.1609e-01,  7.5594e-02,  4.2984e-01,\n",
      "        -6.0675e-02, -1.6645e-01,  1.3505e-01, -2.5153e-01, -1.0624e-01,\n",
      "         1.4267e-01, -5.7441e-02, -2.9146e-01,  1.3726e-01,  1.5721e-01,\n",
      "        -8.1541e-02,  1.0250e-01, -1.7980e-01,  2.9699e-02,  3.6201e-02,\n",
      "        -6.3940e-03, -1.3988e-01,  7.1402e-02,  7.3059e-02, -2.4446e-02,\n",
      "        -1.2914e-01, -9.5205e-02, -3.2620e-01,  1.3743e-01,  8.8643e-02,\n",
      "        -1.7398e-01,  5.7910e-02,  2.2490e-01,  5.9370e-02, -1.3692e-02,\n",
      "        -1.3146e-01, -1.0018e-01, -1.2550e-01,  2.3781e-02, -3.0144e-01,\n",
      "         1.4901e-01, -1.8852e-01, -1.9446e-03])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'torch.Size' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(tensor_query_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(tensor_query_list[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mqueryRNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_query_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# output.forward(trainintensor_query_listData[0][0])\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "Cell \u001b[1;32mIn[66], line 16\u001b[0m, in \u001b[0;36mfullRNN.forward\u001b[1;34m(self, ordered_text)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mThis functions defines forward prop through our RNN network.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mThe input is a tensor of shape (seq_length, batch_size, input_size)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mThe seq_length is number of examples\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Initiates the hidden layer for the whole text\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mordered_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m ordered_text \u001b[38;5;241m=\u001b[39m ordered_text\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adds a batch dimension\u001b[39;00m\n\u001b[0;32m     18\u001b[0m hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, ordered_text\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
     ]
    }
   ],
   "source": [
    "# Step 3 - Pass data into model \n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005 # param, play around with to learn\n",
    "optimizer = torch.optim.SGD(queryRNN.parameters(), lr=learning_rate) #stochastic gradient descent\n",
    "\n",
    "print(tensor_query_list.shape)\n",
    "print(tensor_query_list[0].shape)\n",
    "print(tensor_query_list[0])\n",
    "output = queryRNN.forward(tensor_query_list)\n",
    "# output.forward(trainintensor_query_listData[0][0])\n",
    "\n",
    "print(output)\n",
    "\n",
    "# Step 4 - Evaluate loss function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
